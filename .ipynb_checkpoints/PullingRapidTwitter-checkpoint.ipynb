{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbf73314-d490-4eff-9438-217c78b07a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 new tweets saved to CSV.\n",
      "18 new tweets saved to CSV.\n",
      "No more cursor. Scraping complete.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialise params\n",
    "params = {\n",
    "    \"type\": \"Latest\",\n",
    "    \"count\": \"100\",\n",
    "    \"query\": \"fire AND Malaysia\"\n",
    "}\n",
    "\n",
    "# URL and Headers\n",
    "url = \"https://twitter241.p.rapidapi.com/search-v2\"\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"c7d63f413cmshf2851df4a5e42d1p1ed1bejsn092d86a02e69\",\n",
    "    \"X-RapidAPI-Host\": \"twitter241.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# CSV File Setup\n",
    "csv_file = 'tweets3_data.csv'\n",
    "fieldnames = ['tweet_id', 'tweet_text', 'tweet_created_at', 'tweet_hashtags',\n",
    "              'location', 'user_id', 'user_name', 'user_screen_name',\n",
    "              'verified', 'verification_type', 'user_followers_count',\n",
    "              'professional_type', 'tweet_images']\n",
    "\n",
    "# Create the file if it doesn't exist and write header\n",
    "if not os.path.exists(csv_file):\n",
    "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "seen_ids = set()  # To avoid duplicates\n",
    "next_cursor = None\n",
    "\n",
    "while True:\n",
    "    if next_cursor:\n",
    "        params[\"cursor\"] = next_cursor\n",
    "    elif \"cursor\" in params:\n",
    "        del params[\"cursor\"]  # Remove cursor param for first request\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Request failed with status code:\", response.status_code)\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    tweets = []\n",
    "    next_cursor = None  # Reset before checking again\n",
    "\n",
    "    for entry in data.get('result', {}).get('timeline', {}).get('instructions', []):\n",
    "        if 'entries' in entry:\n",
    "            for item in entry['entries']:\n",
    "                # Tweet data\n",
    "                if item.get('content', {}).get('itemContent', {}).get('itemType') == \"TimelineTweet\":\n",
    "                    tweet = item['content']['itemContent']['tweet_results']['result']\n",
    "\n",
    "                    tweet_legacy = tweet.get('legacy', {})\n",
    "                    hashtags = tweet_legacy.get('entities', {}).get('hashtags', [])\n",
    "                    tweet_id = tweet.get('rest_id', None)\n",
    "\n",
    "                    if tweet_id and tweet_id not in seen_ids:\n",
    "                        seen_ids.add(tweet_id)\n",
    "                        user = tweet.get('core', {}).get('user_results', {}).get('result', {})\n",
    "                        user_legacy = user.get('legacy', {})\n",
    "\n",
    "                        # Extract images from tweet if present\n",
    "                        images = []\n",
    "                        media = tweet_legacy.get('extended_entities', {}).get('media', [])\n",
    "                        for m in media:\n",
    "                            if m.get('type') == 'photo':\n",
    "                                images.append(m.get('media_url_https', ''))\n",
    "                        tweet_images = ','.join(images) if images else 'null'\n",
    "\n",
    "                        tweet_info = {\n",
    "                            'tweet_id': tweet_id,\n",
    "                            'tweet_text': tweet_legacy.get('full_text', ''),\n",
    "                            'tweet_created_at': tweet_legacy.get('created_at', ''),\n",
    "                            'tweet_hashtags': ','.join(tag.get('text', '') for tag in hashtags) if hashtags else 'null',\n",
    "                            'location': user_legacy.get('location', ''),\n",
    "                            'user_id': user.get('rest_id', ''),\n",
    "                            'user_name': user_legacy.get('name', ''),\n",
    "                            'user_screen_name': user_legacy.get('screen_name', ''),\n",
    "                            'verified': user.get('verified', False),\n",
    "                            'verification_type': user.get('verification_type', 'null'),\n",
    "                            'user_followers_count': user_legacy.get('followers_count', 0),\n",
    "                            'professional_type': user.get('professional', {}).get('professional_type', 'null'),\n",
    "                            'tweet_images': tweet_images\n",
    "                        }\n",
    "                        tweets.append(tweet_info)\n",
    "\n",
    "                # Cursor data\n",
    "                if item.get('entryId', '').startswith('cursor-bottom'):\n",
    "                    next_cursor = item['content'].get('value')\n",
    "\n",
    "    # Save tweets\n",
    "    if tweets:\n",
    "        with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writerows(tweets)\n",
    "        print(f\"{len(tweets)} new tweets saved to CSV.\")\n",
    "    else:\n",
    "        print(\"No new tweets found.\")\n",
    "\n",
    "    # If no more cursor, stop\n",
    "    if not next_cursor:\n",
    "        print(\"No more cursor. Scraping complete.\")\n",
    "        break\n",
    "\n",
    "    # Wait before the next request (optional)\n",
    "    time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba0685-9846-48ef-8e07-de5da2d550d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
